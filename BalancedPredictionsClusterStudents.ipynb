{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f22652512d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "conn = sqlite3.connect(\"profiles.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"ATTACH DATABASE 'colleges.db' AS colleges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM colleges.university_profiles AS c JOIN profiles AS p ON c.school = p.school\",conn)\n",
    "max_index = len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_map(df_column):\n",
    "    return {t:i for i, t in enumerate(set(df_column))}\n",
    "\n",
    "def convert_sat_to_act(sat):\n",
    "    if np.isnan(sat):\n",
    "        return np.nan\n",
    "    sat_scores = np.array([990, 1060, 1140, 1210, 1270, 1330, 1390, 1450, 1510, 1560, 1620, 1680, 1740, 1800, 1860, 1920, 1980, 2020, 2080, 2140, 2220, 2290, 2380, 2410])\n",
    "    return np.where(sat < sat_scores)[0][0] + 13\n",
    "    \n",
    "def combine_test_scores(x):\n",
    "    if not np.isnan(x['act']):\n",
    "        return x['act']/36.0\n",
    "    sat = np.array([x['sat_m'], x['sat_r'], x['sat_w']])\n",
    "    return convert_sat_to_act(3*sat[~np.isnan(sat)].mean())/36.0 if len(sat[np.isnan(sat)]) != 3 else np.nan\n",
    "\n",
    "def convert_string(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def combine_avg_test_scores(x):\n",
    "    if not np.isnan(convert_string(x['avg_act'])):\n",
    "        return convert_string(x['avg_act'])/36.0\n",
    "    sat = np.array([convert_string(x['sat_math']), convert_string(x['sat_reading']), convert_string(x['sat_writing'])])\n",
    "    return convert_sat_to_act(3*sat[~np.isnan(sat)].mean())/36.0 if len(sat[np.isnan(sat)]) != 3 else np.nan\n",
    "\n",
    "def map_statuses(x):\n",
    "    status_map = {\"Denied\": 0, \"Deferred\": np.nan, \"Wait-Listed\": np.nan, \"Accepted\": 2, \"Will Attend\": 2}\n",
    "    return status_map[x['status']]\n",
    "\n",
    "def convert_class_rank(x):\n",
    "    s = str(x['class_rank'])\n",
    "    if \" of \" in s:\n",
    "        return float(s[:s.index(\" of \")])/float(s[s.index(\" of \") + 4:])\n",
    "    if \"Top \" in s:\n",
    "        return float(s[4:s.index(\"%\")])/100.0\n",
    "    if \"Bottom \" in s:\n",
    "        return float(s[7:s.index(\"%\")])/100.0\n",
    "    return np.nan\n",
    "\n",
    "def convert_instate_tuition(x):\n",
    "    if \"<br>\" in str(x['cost_attendance']):\n",
    "        instate = x['cost_attendance'].split(\"<br>\")[0]\n",
    "        return instate[instate.index(\"$\")+1:]\n",
    "    else:\n",
    "        return x['cost_attendance']\n",
    "\n",
    "def convert_outstate_tuition(x):\n",
    "    if \"<br>\" in str(x['cost_attendance']):\n",
    "        outstate = x['cost_attendance'].split(\"<br>\")[1]\n",
    "        return outstate[outstate.index(\"$\")+1:]\n",
    "    else:\n",
    "        return x['cost_attendance']\n",
    "\n",
    "def get_tuition(x):\n",
    "    return x['in_state_tuition'] if x['state'] == x['hs_state'] else x['out_state_tuition']\n",
    "\n",
    "def map_hs_types(x):\n",
    "    hs_type_map = {\"Public\": 0, \"Private\": 1, \"Parochial\": 2, \"Home\": 3}\n",
    "    return hs_type_map[x['hs_type']]\n",
    "\n",
    "def map_ins_types(x):\n",
    "    ins_type_map = {\"Public\": 0, \"Private\": 1, \"Private for-profit\": 1, \"&nbsp;\": np.nan}\n",
    "    return ins_type_map[x['institution_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up points\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "df.fillna(value=pd.np.nan, inplace=True)\n",
    "df['avg_act'] = df['avg_act'].map(lambda x: str(x).strip('-'))\n",
    "df['test_score'] = df.apply(combine_test_scores, axis=1)\n",
    "df['avg_test_score'] = df.apply(combine_avg_test_scores, axis=1)\n",
    "df['class_rank'] = df.apply(convert_class_rank, axis=1)\n",
    "df['institution_type'] = df.apply(map_ins_types, axis=1)\n",
    "df['in_state_tuition'] = df.apply(convert_instate_tuition, axis=1)\n",
    "df['out_state_tuition'] = df.apply(convert_outstate_tuition, axis=1)\n",
    "#df['tuition'] = df.apply(get_tuition, axis=1)\n",
    "df['status'] = df.apply(map_statuses, axis=1)\n",
    "\n",
    "for col in ['cost_attendance','school', 'city', 'sat_m', 'sat_r', 'sat_w', 'act', 'sat_math', 'sat_reading', 'sat_writing', 'avg_act', 'gpa_w']:\n",
    "    df = df.drop(col, axis=1)\n",
    "df = df.dropna()#subset=['test_score','avg_test_score','gpa_uw','class_rank','hs_state','hs_type','institution_type'])\n",
    "\n",
    "df['hs_type'] = df.apply(map_hs_types, axis=1)\n",
    "replace_columns = ['hs_state', 'state', 'gender']\n",
    "for col in replace_columns:\n",
    "    df[col].replace(get_type_map(df[col]), inplace=True)\n",
    "    \n",
    "dfc = df.copy()\n",
    "df_plain = df.copy()\n",
    "for col in ['avg_gpa','hs_state','hs_type','avg_test_score','state','average_freshman_aid','admission_rate','faculty_total','international_percent','institution_type','female_percentage','year','gender','status','eaed','legacy','athlete','in_state_tuition','out_state_tuition']:\n",
    "    dfc = dfc.drop(col, axis=1)\n",
    "\n",
    "def getNextTableIndex(index,j):\n",
    "    isValid = False\n",
    "    while(not isValid):\n",
    "        try:\n",
    "            dfc['class_rank'][index]\n",
    "            return index, j+1\n",
    "        except:\n",
    "            index += 1\n",
    "\n",
    "print(\"Setting up points\")\n",
    "points = []\n",
    "i = 0\n",
    "j=0\n",
    "while i < 97686:\n",
    "    i, j = getNextTableIndex(i,j)\n",
    "    point = []\n",
    "    for col in dfc.columns.values:\n",
    "        point.append(dfc[col].get(i))\n",
    "    points.append(point)\n",
    "    i += 1\n",
    "print(\"Done\")\n",
    "        \n",
    "cluster = KMeans(n_clusters=1000, max_iter=500).fit(points)\n",
    "\n",
    "print(\"Assigning clusters\")\n",
    "i = 0\n",
    "j = 0\n",
    "while i < 97686:\n",
    "    label = cluster.labels_[j]\n",
    "    i, j = getNextTableIndex(i,j)\n",
    "    for c,col in enumerate(dfc.columns.values):\n",
    "        dfc.set_value(i, col, cluster.cluster_centers_[label][c])\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['gpa_uw', 'class_rank', 'test_score']:\n",
    "    df = df.drop(col, axis=1)\n",
    "\n",
    "df = df.join(dfc, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "k = 1\n",
    "df0 = df[df.status == 0]\n",
    "df2 = df[df.status == 2].sample(n = int(k*len(df0)))\n",
    "df_final = pd.concat([df0, df2])\n",
    "X = df_final.drop('status', axis=1)\n",
    "y = df_final['status']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8),max_iter=1000)\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = cross_val_predict(mlp, X, y, cv = 4)\n",
    "\n",
    "# print(classification_report(y,y_pred))\n",
    "\n",
    "# logisticRegr = LogisticRegression()\n",
    "\n",
    "# y_pred = cross_val_predict(logisticRegr, X, y, cv = 4)\n",
    "\n",
    "# print(classification_report(y,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "mlp.fit(X_train1,y_train1)\n",
    "predictions = mlp.predict(X_test1)\n",
    "print(confusion_matrix(y_test1,predictions))\n",
    "print(classification_report(y_test1,predictions))\n",
    "\n",
    "# logisticRegr = LogisticRegression()\n",
    "# logisticRegr.fit(X_train1, y_train1)\n",
    "# score = logisticRegr.score(X_test1, y_test1)\n",
    "# print(\"Logistic Regression Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do: Jake and Marco\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
