{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f0ec65dda40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "conn = sqlite3.connect(\"profiles.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"ATTACH DATABASE 'colleges.db' AS colleges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM colleges.university_profiles AS c JOIN profiles AS p ON c.school = p.school\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_map(df_column):\n",
    "    return {t:i for i, t in enumerate(set(df_column))}\n",
    "\n",
    "def convert_sat_to_act(sat):\n",
    "    if np.isnan(sat):\n",
    "        return np.nan\n",
    "    sat_scores = np.array([990, 1060, 1140, 1210, 1270, 1330, 1390, 1450, 1510, 1560, 1620, 1680, 1740, 1800, 1860, 1920, 1980, 2020, 2080, 2140, 2220, 2290, 2380, 2410])\n",
    "    return np.where(sat < sat_scores)[0][0] + 13\n",
    "    \n",
    "def combine_test_scores(x):\n",
    "    if not np.isnan(x['act']):\n",
    "        return x['act']/36.0\n",
    "    sat = np.array([x['sat_m'], x['sat_r'], x['sat_w']])\n",
    "    return convert_sat_to_act(3*sat[~np.isnan(sat)].mean())/36.0 if len(sat[np.isnan(sat)]) != 3 else np.nan\n",
    "\n",
    "def convert_string(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def combine_avg_test_scores(x):\n",
    "    if not np.isnan(convert_string(x['avg_act'])):\n",
    "        return convert_string(x['avg_act'])/36.0\n",
    "    sat = np.array([convert_string(x['sat_math']), convert_string(x['sat_reading']), convert_string(x['sat_writing'])])\n",
    "    return convert_sat_to_act(3*sat[~np.isnan(sat)].mean())/36.0 if len(sat[np.isnan(sat)]) != 3 else np.nan\n",
    "\n",
    "def map_statuses(x):\n",
    "    status_map = {\"Denied\": 0, \"Deferred\": np.nan, \"Wait-Listed\": np.nan, \"Accepted\": 1, \"Will Attend\": 1}\n",
    "    return status_map[x['status']]\n",
    "\n",
    "def convert_class_rank(x):\n",
    "    s = str(x['class_rank'])\n",
    "    if \" of \" in s:\n",
    "        return float(s[:s.index(\" of \")])/float(s[s.index(\" of \") + 4:])\n",
    "    if \"Top \" in s:\n",
    "        return float(s[4:s.index(\"%\")])/100.0\n",
    "    if \"Bottom \" in s:\n",
    "        return float(s[7:s.index(\"%\")])/100.0\n",
    "    return np.nan\n",
    "\n",
    "def convert_instate_tuition(x):\n",
    "    if \"<br>\" in str(x['cost_attendance']):\n",
    "        instate = x['cost_attendance'].split(\"<br>\")[0]\n",
    "        return instate[instate.index(\"$\")+1:]\n",
    "    else:\n",
    "        return x['cost_attendance']\n",
    "\n",
    "def convert_outstate_tuition(x):\n",
    "    if \"<br>\" in str(x['cost_attendance']):\n",
    "        outstate = x['cost_attendance'].split(\"<br>\")[1]\n",
    "        return outstate[outstate.index(\"$\")+1:]\n",
    "    else:\n",
    "        return x['cost_attendance']\n",
    "\n",
    "def get_tuition(x):\n",
    "    return x['in_state_tuition'] if x['state'] == x['hs_state'] else x['out_state_tuition']\n",
    "\n",
    "def map_hs_types(x):\n",
    "    hs_type_map = {\"Public\": 0, \"Private\": 1, \"Parochial\": 2, \"Home\": 3, np.nan: np.nan}\n",
    "    return hs_type_map[x['hs_type']]\n",
    "\n",
    "def map_ins_types(x):\n",
    "    ins_type_map = {\"Public\": 0, \"Private\": 1, \"Private for-profit\": 1, \"&nbsp;\": np.nan}\n",
    "    return ins_type_map[x['institution_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "df.fillna(value=pd.np.nan, inplace=True)\n",
    "df['avg_act'] = df['avg_act'].map(lambda x: str(x).strip('-'))\n",
    "df['test_score'] = df.apply(combine_test_scores, axis=1)\n",
    "df['avg_test_score'] = df.apply(combine_avg_test_scores, axis=1)\n",
    "df['class_rank'] = df.apply(convert_class_rank, axis=1)\n",
    "df['institution_type'] = df.apply(map_ins_types, axis=1)\n",
    "df['status'] = df.apply(map_statuses, axis=1)\n",
    "df['hs_type'] = df.apply(map_hs_types, axis=1)\n",
    "df['in_state_tuition'] = df.apply(convert_instate_tuition, axis=1)\n",
    "df['out_state_tuition'] = df.apply(convert_outstate_tuition, axis=1)\n",
    "df['tuition'] = df.apply(get_tuition, axis=1)\n",
    "\n",
    "c0 = .5\n",
    "c1 = .4\n",
    "c2 = .1\n",
    "df.['split_metric'] = c0*df['test_score'] + c1*df['gpa_uw'] + c2*(1-df['class_rank'])\n",
    "\n",
    "for col in [',in_state_tuition',',out_state_tuition','cost_attendance','school', ',city', 'sat_m', 'sat_r', 'sat_w', 'act', 'sat_math', 'sat_reading', 'sat_writing', 'avg_act', ',gpa_w']:\n",
    "    try:\n",
    "        df = df.drop(col, axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "df = df.dropna()\n",
    "replace_columns = ['hs_state', 'state', 'gender', 'city']\n",
    "for col in replace_columns:\n",
    "    try:\n",
    "        df[col].replace(get_type_map(df[col]), inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "k = 1\n",
    "df0 = df[df.status == 0]\n",
    "df2 = df[df.status == 1].sample(n = int(k*len(df0)))\n",
    "df_final = pd.concat([df0, df2])\n",
    "df_final.sort_values(by=['split_metric'])\n",
    "X = df_final.drop('status', axis=1)\n",
    "X = X.drop('split_metric', axis=1)\n",
    "y = df_final['status']\n",
    "    \n",
    "mlps = []\n",
    "clusters = 5\n",
    "for i in range(0,len(X),len(X)/5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[i:i+len(X)/5], y[i:i+len(X)/5])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(8,8,8),max_iter=1000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    pred = mlp.predict(X_test)\n",
    "    mlps.append(score(y_test,pred))\n",
    "\n",
    "# logisticRegr = LogisticRegression()\n",
    "# logisticRegr.fit(X_train, y_train)\n",
    "# pred = logisticRegr.predict(X_test)\n",
    "# logs.append(score(y_test,pred))\n",
    "\n",
    "# ridgeRegr = RidgeClassifier()\n",
    "# ridgeRegr.fit(X_train, y_train)\n",
    "# pred = ridgeRegr.predict(X_test)\n",
    "# rids.append(score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8492339444674628, 0.8486672710788757, 0.8486290091260691)\n",
      "(0.8398154600964157, 0.8381368993653672, 0.8379660180650446)\n",
      "(0.8334930871447289, 0.8299138712601994, 0.8294948514558331)\n"
     ]
    }
   ],
   "source": [
    "totals = (sum([x[3][0] for x in mlps]),sum(x[3][1] for x in mlps))\n",
    "sums = [([x[0][0]*x[3][0], x[0][1]*x[3][1]],[x[1][0]*x[3][0], x[1][1]*x[3][1]],[x[2][0]*x[3][0], x[2][1]*x[3][1]]) for x in mlps]\n",
    "sums = ((sum([x[0][0] for x in sums])+sum([x[0][1] for x in sums]))/sum(totals),\n",
    "        (sum([x[1][0] for x in sums])+sum([x[1][1] for x in sums]))/sum(totals),\n",
    "        (sum([x[2][0] for x in sums])+sum([x[2][1] for x in sums]))/sum(totals))\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
